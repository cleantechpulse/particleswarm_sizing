{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import RadioSimulator\n",
    "import datetime\n",
    "import sys, time, copy, os, random, math, pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mpl_colors\n",
    "%matplotlib inline\n",
    "\n",
    "# Plotting setup\n",
    "fs = 14\n",
    "plt.rc('font',family='Times New Roman')\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "#mpl.rc('text', usetex = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to be able to parallelize:\n",
    "\n",
    "- Update particle position\n",
    "- Compute cost of new position\n",
    "- Return all particle information:\n",
    "   - current position, \n",
    "   - current velocity\n",
    "   - current error\n",
    "   - best position\n",
    "   - best error\n",
    "\n",
    "Try:\n",
    "- Pass the swarm to a function- each particle will be passed to a process\n",
    "- The function updates the particle's position and error, and returns the particle with updated information\n",
    "\n",
    "For our problem, we can ultimately roll the RadioSimulator into each Particle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, minx, maxx, seed, initPosition=None, initCost = None):\n",
    "        self.sim = RadioSimulator.RadioSimulator(radioFile = '../Data/PowerMEMS_Sample_Data_em_20160707.csv')\n",
    "        self.minx = minx\n",
    "        self.maxx = maxx\n",
    "        self.rnd = random.Random(seed)\n",
    "        dim = len(minx)\n",
    "        self.position = np.zeros(dim)\n",
    "        self.velocity = np.zeros(dim)\n",
    "\n",
    "        # If we dictate an initial position, we will accept that as our position. \n",
    "        #  Otherwise, we will randomly generate one. \n",
    "        if initPosition is not None:\n",
    "            self.position = initPosition\n",
    "            self.velocity = [((maxx[i] - minx[i]) * self.rnd.random() + minx[i])  for i in range(dim)]\n",
    "            self.cost = initCost\n",
    "        else:    \n",
    "            for i in range(dim):\n",
    "                self.position[i] = ((maxx[i] - minx[i]) * self.rnd.random() + minx[i])\n",
    "                self.velocity[i] = ((maxx[i] - minx[i]) * self.rnd.random() + minx[i])\n",
    "            self.cost = evaluateCost(self)\n",
    "\n",
    "        self.best_part_cost = self.cost # best error\n",
    "        self.best_part_pos = copy.copy(self.position)\n",
    "        \n",
    "        # Placeholders for later updating\n",
    "        self.best_swarm_cost = 0.0\n",
    "        self.best_swarm_pos = copy.copy(self.position)\n",
    "\n",
    "    def set_position(self, newPos, cost=None):\n",
    "        self.position = newPos\n",
    "        if cost is not None:\n",
    "            self.cost = cost\n",
    "        else:\n",
    "            self.cost = evaluateCost(self)\n",
    "            \n",
    "        self.best_part_pos = copy.copy(self.position) \n",
    "        self.best_part_cost = self.cost # best error\n",
    "\n",
    "def evaluateCost(myParticle):\n",
    "    a = myParticle.position\n",
    "    initVariables = {'TEGserial':a[0], 'TEGparallel':a[1], 'batts':a[2], 'caps':a[3], 'SOC':a[4], 'V_b':a[5], 'V_c':a[6]}\n",
    "    return myParticle.sim.computeCost(initVariables)\n",
    "    err = 0.0\n",
    "    for i in range(len(myParticle.position)):\n",
    "        xi = myParticle.position[i]\n",
    "        err += (xi * xi) - (10 * math.cos(2 * math.pi * xi)) + 10\n",
    "    return err        \n",
    "        \n",
    "def stepForward(myParticle):\n",
    "    ## Initialization\n",
    "    w = 0.729    # inertia\n",
    "    c1 = 1.49445 # cognitive (particle)\n",
    "    c2 = 1.49445 # social (swarm)\n",
    "    dim = len(myParticle.position)\n",
    "    rnd = random.Random(0)\n",
    "    \n",
    "    # compute new velocity of curr particle, in each dimension\n",
    "    for k in range(dim): \n",
    "        r1 = rnd.random()    # randomizations\n",
    "        r2 = rnd.random()\n",
    "\n",
    "        # New velocity = w * inertia + c1 * own best + c2 * swarm best\n",
    "        myParticle.velocity[k] = ( (w * myParticle.velocity[k]) + \n",
    "                                 (c1 * r1 * (myParticle.best_part_pos[k] - myParticle.position[k])) +  \n",
    "                                 (c2 * r2 * (myParticle.best_swarm_pos[k] - myParticle.position[k])) )  \n",
    "\n",
    "        # Make sure that the particles stay within the (minx, maxx) bounds in each dimension\n",
    "        if (maxx[k] - myParticle.position[k]) < myParticle.velocity[k]:\n",
    "              myParticle.velocity[k] = maxx[k] - myParticle.position[k]\n",
    "        elif (minx[k] - myParticle.position[k]) > myParticle.velocity[k]:\n",
    "              myParticle.velocity[k] = minx[k] - myParticle.position[k]\n",
    "\n",
    "    # compute new position using new velocity\n",
    "    myParticle.position += myParticle.velocity\n",
    "\n",
    "    # compute error of new position\n",
    "    myParticle.cost = evaluateCost(myParticle)\n",
    "\n",
    "    # is new position a new best for the particle?\n",
    "    if myParticle.cost < myParticle.best_part_cost:\n",
    "        myParticle.best_part_cost = myParticle.cost\n",
    "        myParticle.best_part_pos = copy.copy(myParticle.position)\n",
    "\n",
    "    return (myParticle.cost, myParticle)\n",
    "        \n",
    "def Solve(max_epochs, n, minx, maxx, initValues=None, initCostList=None):\n",
    "    # max_epochs: Number of simulation epochs, i.e. flight time steps\n",
    "    # n : Number of particles. If initial values are used, make sure n<=initValues\n",
    "    # dim: dimensionality of Rastriggin's function\n",
    "    # minx, maxx: Assuming that the simulation is in a hypercube defined by the range (minx, maxx) in each dimension\n",
    "    # initValues: A Numpy array, with columns of position variables and each \n",
    "    \n",
    "    ## Create Swarm\n",
    "    if initValues is not None:\n",
    "        swarm = [Particle(minx, maxx, i, initValues[i], initCostList[i]) for i in range(n)]\n",
    "    else: \n",
    "        swarm = [Particle(minx, maxx, i) for i in range(n)]\n",
    "            \n",
    "    ## Identify the best cost in the initial batch\n",
    "    best_swarm_cost = float('inf') # High initial value    \n",
    "    for i in range(n): # See what the actual best position is so far\n",
    "        if swarm[i].cost < best_swarm_cost:\n",
    "            best_swarm_cost = swarm[i].cost\n",
    "            best_swarm_pos = copy.copy(swarm[i].position) \n",
    "\n",
    "    # Now that we've identified the best position, broadcast that to all the particles\n",
    "    for i in range(n):\n",
    "        swarm[i].best_swarm_cost = best_swarm_cost\n",
    "        swarm[i].best_swarm_pos = best_swarm_pos\n",
    "        \n",
    "    ## Done with initialization of the swarm- now move on to the actual work!\n",
    "        \n",
    "    rnd = random.Random(0)\n",
    "    myPool = Pool()\n",
    "    dim = len(minx)\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs:\n",
    "\n",
    "        # Map: Parallelize computation of the new position for each particle\n",
    "        # - Return a tuple with (error, particle)\n",
    "        mapResults = myPool.map(stepForward,swarm)\n",
    "        \n",
    "        # Reduce:\n",
    "        #  - Compute which error is minimal\n",
    "        #  - if that error is an improvement\n",
    "        #     - identify the position at which it occured\n",
    "        #     - Broadcast that position and error to all the particles in the swarm\n",
    "\n",
    "        (costs, swarm) = tuple(zip(*mapResults))\n",
    "        minCost = min(costs)\n",
    "        # Check whether the error has improved\n",
    "        if minCost < best_swarm_cost:\n",
    "            best_swarm_cost = minCost\n",
    "            minIdx = costs.index(minCost)\n",
    "            best_swarm_pos = copy.copy(swarm[minIdx].position)\n",
    "        # If the error has improved, update each particle with that information.\n",
    "        for i in range(n):\n",
    "            swarm[i].best_swarm_cost = best_swarm_cost\n",
    "            swarm[i].best_swarm_pos = best_swarm_pos\n",
    "\n",
    "        epoch += 1\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Epoch = \" + str(epoch) + \" best error = %.3f\" % best_swarm_cost)\n",
    "            sys.stdout.flush()\n",
    "            pickle.dump(swarm, open( \"swarm.pkl\", \"wb\" ))\n",
    "    \n",
    "    return best_swarm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at 2016-07-11 17:39:01.626516\n",
      "Epoch = 1 best error = 172.000\n",
      "Epoch = 2 best error = 172.000\n",
      "Epoch = 3 best error = 172.000\n",
      "Done execution in 52.33 seconds\n",
      "\n",
      "Best solution found:[  6.   25.   21.    1.    0.4   0.    1.8]\n"
     ]
    }
   ],
   "source": [
    "num_particles = 10\n",
    "# initial_successes = int(num_particles * 0.2)\n",
    "max_epochs = 3\n",
    "\n",
    "#  x = [  p,   s ,  b ,   c, SOC, V_b, V_c]\n",
    "minx = [  1,   1 ,  0 ,   0, 0.2,  0 ,  0 ]\n",
    "maxx = [100,  100, 100, 100, 0.8, 2.6, 3.6]\n",
    "\n",
    "# Load a set of points with which to initialize some of the particles.  These will have coordinates in a Numpy array.\n",
    "# gridsearchResults = pd.read_csv(\"../Results/gridSearchSuccesses_2016-07-08_10_07.csv\", index_col=0)\n",
    "# initPoints = gridsearchSuccesses.sort_values(by='cost')[0:initial_successes]\n",
    "\n",
    "gridSearchResults = pd.read_csv(\"../Results/gridSearchAllResults_2016-07-10.csv\", index_col=0)\n",
    "initPoints = gridSearchResults[gridSearchResults['cost']<float('inf')]\n",
    "num_particles = initPoints.shape[0]\n",
    "\n",
    "num_particles = 10\n",
    "\n",
    "initVariables = initPoints[['TEGparallel','TEGserial','batts','caps','SOC','V_b','V_c']].values  # Get the values in the right order\n",
    "initCosts = initPoints['cost'].values\n",
    "\n",
    "print(\"Started at %s\"%datetime.datetime.now())\n",
    "sys.stdout.flush()\n",
    "starttime = time.time()\n",
    "best_position = Solve(max_epochs, num_particles, minx, maxx, initValues=initVariables, initCostList=initCosts)\n",
    "print(\"Done execution in %.2f seconds\"%(time.time()-starttime))\n",
    "\n",
    "print(\"\\nBest solution found:\" + str(best_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarioList = range(75000)\n",
    "len(scenarioList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 14999)\n",
      "(15000, 29999)\n",
      "(30000, 44999)\n",
      "(45000, 59999)\n",
      "(60000, 74999)\n"
     ]
    }
   ],
   "source": [
    "scenarioList = range(75000)\n",
    "len(scenarioList)\n",
    "\n",
    "batches = 5\n",
    "batchSize = len(scenarioList)/batches\n",
    "\n",
    "\n",
    "for j in np.arange(0,len(scenarioList),batchSize):\n",
    "    print(j,j+batchSize-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load Swarm from saved file\n",
    "import pickle \n",
    "\n",
    "mySwarm = pickle.load(open('swarm_20160712.pkl'))\n",
    "\n",
    "n = len(mySwarm)\n",
    "\n",
    "best_swarm_cost = float('inf')\n",
    "for i in range(n): # See what the actual best position is so far\n",
    "    if mySwarm[i].best_part_cost < best_swarm_cost:\n",
    "        best_swarm_cost = mySwarm[i].best_part_cost\n",
    "        best_swarm_pos = copy.copy(mySwarm[i].best_part_pos) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swarm_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1. ,  30. ,  21. ,   1. ,   0.4,   0. ,   1.8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_swarm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
